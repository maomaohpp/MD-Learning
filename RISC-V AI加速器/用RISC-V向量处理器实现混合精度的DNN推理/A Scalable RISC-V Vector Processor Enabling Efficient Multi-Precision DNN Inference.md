# A Scalable RISC-V Vector Processor Enabling Efficient Multi-Precision DNN Inference

### SPEED架构

#### 自定义指令

$VSACFG$

向量配置指令，位后续指令提供必要信息，如数据精度（4~16位）和数据流策略（FF/CF策略）。这些信息被编码在zimm9和uimm5中，为后续RISC-V向量指令集（RVV）和定指指令的处理做准备。

$VSALD$

向量加载指令，负责从外部存储器的及地址加载数据，并将其存储到指定目标地址的向量寄存器堆（VRF）中。与标准RVV加载指令VLE的有序分配操作数不同，从外部寄存器加载的数据被广播到每个lane，以提高数据重用率。

$VSAM$

向量运算指令，有效利用了数据级并行性。VASM分别从VRF中的基地址vs1和vs2请求数据。执行结果存储在VRF中的累加地址Acc Addr中。

#### 硬件架构

![F-1](.\图片\F-2.png)

1. 向量指令译码单元（VIDU）用来对定制指令和标准RVV指令进行译码。

2. 向量加载单元（VLDU）通过广播或有序分配来分发从存储器中加载的数据。

3. 向量处理器（lane）是主要计算部件，由lane序列化器、VRF、可扩展阵列单元（SAU）和算数逻辑单元（ALU）组成。

4. 可扩展阵列单元（SAU）是一种高度灵活且参数化的多精度计算单元。由操作数请求器、队列和可扩展阵列核（SA Core）组成。

   - 操作数请求器由地址生成器和请求仲裁器组成，通过同时生成请求地址和优先处理数据请求，实现高效的数据访问；

   - 队列负责缓冲计算所需的数据，包括输入、权重、累加部分结果和输出；

   - SA Core是一个可配置的二维处理单元（PE）阵列，由参数$TILE\_C$和$TILE\_R$决定。

     **SA Core具有三级并行**：每个PE内部在输入通道维度上并行；每个通道内的PE阵列之间在输出通道维度上并行；在特征图的h维度上并行。

     **每个PE由16个4位乘法器组成，可动态组合以执行16位精度的乘法累加操作（MAC），4组8位精度的MAC或16组4位精度的MAC。（<font color='RedOrange'>MD芯片中的浮点乘法器是否也可以按照这种方式做，以实现多精度的推理？</font>）**

#### 数据流映射

![F-1](.\图片\F-1.png)

图2中，权重核被设置为$3\times3$大小。

**如图2（a）为输入的预取：**

在两次的卷积操作过程中，16位精度的输入（x16）元素被预取到向量寄存器堆（VRF）中。

特征图维度预取策略（FF）：适用于内核尺寸较大的卷积层

1. 在FF策略中，在单个通道上预取$4\times 4$​​个元素，减少了片外数据移动。
2. 在两次卷积运算过程中，SAU会请求并计算这些预取的元素。
3. 当第一次卷积完成后结果会被写回VRF中，在下一次中红框和蓝框中的元素被重用

显然，这种写回多次卷积结果的方法占据了VRF的大部分存储空间，而且每一次完成后传输部分结果时会浪费额外时间。



通道维度预取策略（CF）：适用于内核尺寸较小的卷积层

1. 在CF策略中，两次卷积运算从两个输入通道预取元素。
2. 第一次和第二次分别请求预取元素的第一和第二输入通道进行计算，两次的结果在SAU中累加，不写回VRF中。

**图2（b）和（c）为两次卷积操作中预取和请求16位权重（W16）和8位权重（W8）的过程：**

在W16+CF策略中（图2（b）），沿输出通道维度预取2个权重，以增强单通道内的并行计算，其中权重的数量由$TILE\_C$决定。在第一次卷积结束后，权重的第二通道元素参与计算。

在W8+FF策略中（图2（c）），W8元素在输入通道维度上的并行度是4，从而提高了计算效率。当第一次卷积计算完成后，权重会在第二次计算中重用，减少了片外数据移动。

### 性能评估

使用Ara为baseline，使用VGG16、ResNet18、GoogLeNet和SqueezeNet进行测试。**使用周期精确的模拟器QuestaSim。**

SPEED和Ara都使用4lanes、向量长度都为4096bits。SPEED的每个lane中SAU的$TILE\_R$和$TILE\_C$的大小为4.

![F-1](.\图片\F-3.png)

在16为精度下， 使用各种策略在SPEED上对采用不同卷积核大小的GoogleNet进行了分层评估。

**混合策略会在每一层动态选择性能最佳的FF或CF策略。相比于只有FF或CF，性能分别提升了1.88倍和1.38倍。**

图3表明CF策略更适用于conv1x1，而FF策略适用于其他卷积核，其中convKxK表示核大小为K的卷积算子。

![F-4](.\图片\F-4.png)

图4所示，SPEED在16位和8位精度条件下的平均面积效率分别比Ara提高了2.77倍和6.39倍。此外，SPEED还实现了高效的4位推理。

#### 综合结果分析

![F-4](.\图片\F-5.png)

![F-Table1](.\图片\F-Table1.png)
# Gemmini: Enabling Systematic Deep-Learning Architecture Evaluation via Full-Stack Integration (DAC 2021)

项目地址：https://github.com/ucb-bar/gemmini

#### 问题

现有的加速器对决定整个SoC和软件栈的系统级参数的研究不足。现有的DNN生成器几乎不支持全栈编程接口（可提供加速器的高级和低级控制），也几乎不支持完整的SoC集成。

#### 工作量

1）设计了一个开源的，全栈DNN加速器设计基础架构Gemmini，以便对深度学习架构进行系统评估。（Gemmini开发了灵活的硬件模板、多层软件栈和集成的SoC环境）

2）使用基于FPGA的性能测量和用于性能效率分析的商用ASIC综合流程，对Gemmini生成的加速器进行严格评估

3）展示了Gemmini基础架构能够对运行DNN工作负载的SoC进行系统-加速器协同设计，包括为DNN加速器设计高效的虚拟地址转换方案，以及在共享缓存层次结构中调配内存资源

### 架构

![Gemmini-1](.\图片\Gemmini-1.png)

Gemmini架构的核心是一个空间阵列单元，其中包含空间分布式处理单元（PE），每个处理单元执行点乘和累加。阵列从本地明精确管理的便签式SRAM读取数据，同时将结果写入本地累加器存储。Gemmini还可以通过一系列可编程的外围电路，支持其他常用的DNN内核，如池化、非线性激活（ReLU、ReLU6）和矩阵标量乘法。**Gemmini可以通过集成RISC-V CPU实现对加速器的配置和编程。**

![Gemmini-2](.\图片\Gemmini-2.png)

空间阵列由两级层次结构组成，以便为不同微体系结构提供灵活的模板。

第一级由矩阵$tiles$阵列组成，每个tile之间通过流水线寄存器连接。

每个tiles由矩形PE阵列组成，tile中的每个PE间通过组合逻辑连接（没有流水线寄存器）。每个PE每周期可以执行一个乘加操作，使用权重或输出静态数据流。

**每个PE和tile仅与邻居共享输入和输出。**

![Gemmini-3](.\图片\Gemmini-3.png)

图3展示了Gemmini的两级层次结构如何提供灵活性，以支持从类似于TPU的全流水线架构到类似于NVDLA的并行向量引擎。

用256个PE综合了这两种设计。由于类似于TPU的设计有更短的MAC链，所以其频率比类似于NVDLA的设计高出2.7倍，但是消耗了1.8倍的面积和3倍的功耗，由于其流水线寄存器。

### 编程支持

Gemmini提供了多级软件流以支持不同的编程场景。

在高层，Gemmini包含一个按钮式软件流程，可读取ONNX文件格式中的DNN描述，并生成可运行它们的软件二进制文件，将尽可能多的内核映射到Gemmini生成的加速器上。

在底层，也可以通过C/C++ API对生成的加速器进行编程，并为常见的DNN内核调整函数。这些函数必须根据SRAM大小和其他参数，针对不同硬件实例进行不同的调整。因此，**每次生成新的加速器时，Gemmini都会生成一个附带的包含各种参数的头文件**，如空间阵列的尺寸、支持的数据流已经包含的计算块（池化、im2col或转至块）。

#### 数据存储和映射

Gemmini在运行时计算循环tile的大小，这些tile大小决定了在执行tile矩阵乘法、卷积、残差加法等内核时，在DRAM、L2和SRAM之间移动数据的时间和数量。

#### 虚拟内存支持

Gemmini也支持使用者共同设计和配置自己的虚拟地址转换系统。

### 系统支持

**Gemmini允许在Chipyard框架中将RISC-V CPU与Gemmini生成的加速器集成在一起。这些CPU可以运行多个计算密集型应用，甚至可以向Gemmini生成的加速器发送命令。**SoC还可以配置为多个主机CPU和Gemmini生成的加速器。图5是双核系统的一个示例。

![Gemmini-5](.\图片\Gemmini-5.png)

**基于RISC-V的全SoC集成还实现了对软件栈的深度支持**，这样就可以轻松地评估Gemmini生成地加速器在运行完整软件堆栈（包括操作系统本身）时的性能。**这样就能在上下文切换、页表换出和其他意外事件随时可能发生的现实环境中，对加速器工作负载进行早期探索。**

### Gemmini的评测

![Gemmini-7](.\图片\Gemmini-7.png)

### Gemmini案例研究

展示了Gemmini如何实现全系统的代码设计

#### 虚拟地址转换

Gemmini可以在调整加速器和SoC的过程中反复使用各种地址转换方案。

![Gemmini-8](.\图片\Gemmini-8.png)

将Gemmini配置为两级TLB缓存，其中一级时加速器专用TLB，另一级是二级缓存中更大的共享TLB。

图8（a）展示了加速器专用TLB相比较更大的二级共享缓存对端到端性能的影响更大。



虽然调整TLB大小可以提高命中率，但在图8（a）所示的测试中，加速器专用TLB延迟仍然长达几个周期。通过使用一个寄存器用于缓存读操作的上次 TLB 命中，另一个寄存器用于缓存写操作的 TLB 命中。这些过滤寄存器可将连续访问同一页的TLB命中延迟降低至0周期。如图8（b）所示，最终发现一个配备了过滤寄存器但没有昂贵的共享L2 TLB，只有4条目加速器专用TLB的系统只比记录中的最高性能低2%。

#### 系统级资源划分

Gemmini还能为现实的DNN工作负载实现应用-系统协同设计。

该案例研究描述了一个系统级设计决策：基于应用特性的内存分区。

现实中的DNN应用具有不同类型的层，不同类型的层计算要求各不相同。

以ResNet50为例，其包含卷积、矩阵乘法和残差加法，表现出截然不同的计算模式。卷积的运算强度比较高；矩阵乘法的运算强度较低；而残差加法几乎完全没有数据重用。

在六种不同的SoC配置上运行ResNet50推理。图9（a）中演示的三种推理，以及在单核和双核SoC重复使用。双核SoC并行运行两个ResNet50工作负载，单核只运行一个。

Baseline的每个内核都有一个256KB的scratchpad和一个256KB的累加器，以及一个1MB的共享L2 Cache。scratchpad和累加器是加速器专用，而L2 Cache是所有CPU和加速器共享。假设有1MB的额外SRAM可以分配给内存系统，决策将其分给加速器内存还是L2 Cache。

![Gemmini-9](.\图片\Gemmini-9.png)

图9（b）所示的单核情况下，卷积和矩阵乘法性能的提高足以使增加加速器内存的性能提升高于增加给L2 Cache。

图9（c）所示的双核情况下，由于残差加法都会从共享二级缓存中驱逐另一个内核所期待的输入层，从而增加了内存限制的残差加法层的延迟。双核BigL2配置增加了共享缓存的大小，缓解了这种征用现象，使得整体性能的提升由于增加内存给加速器。